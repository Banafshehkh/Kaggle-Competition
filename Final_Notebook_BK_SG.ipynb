{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXVNA5QjM65nNXv1+50PXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Banafshehkh/Kaggle-Competition/blob/main/Final_Notebook_BK_SG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFjPnHmW4azk"
      },
      "outputs": [],
      "source": [
        "#Authors: Banafsheh Khazali, Shokoofa Ghods\n",
        "#Date: March 09, 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GoogleNet**"
      ],
      "metadata": {
        "id": "Zf5qjzFg4tOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Classifier_GoogleNet.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Fy0gzrWHTIPRjUkSrgqG4DEmMwOVy8xF\n",
        "\"\"\"\n",
        "\n",
        "# Author: Banafsheh Khazali and Shokoofa Ghods\n",
        "# Date: March 06, 2023\n",
        "\n",
        "\"\"\"## Libraries\"\"\"\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip -q \"/content/drive/MyDrive/Data/Dataset.zip\" -d \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "\"\"\"# Load the csv file containing the image file names and corresponding labels\"\"\"\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "data\n",
        "\n",
        "np_data = data.values\n",
        "\n",
        "\"\"\"# Define Transformers\"\"\"\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p = 0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "])\n",
        "\n",
        "\"\"\"# Map images to their labels\"\"\"\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Get the filename and label for the current index\n",
        "        filename = self.data[index][0]\n",
        "        label = self.data[index][1]\n",
        "        \n",
        "        # Load the image and apply the transformations\n",
        "        image = Image.open('/content/drive/MyDrive/train/' + filename)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            label = torch.tensor(label)\n",
        "        \n",
        "        # Return the image and label as tensors\n",
        "        return image, label\n",
        "\n",
        "    def number_of_classes(self):\n",
        "      return self.data[:,1].max() + 1\n",
        "\n",
        "def visualization(image, label):\n",
        "  plt.figure(figsize= (10,8))\n",
        "  plt.imshow(image.permute(1,2,0))\n",
        "  plt.title(label.item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"# Load the train dataset from the folder\"\"\"\n",
        "\n",
        "train_dataset = CustomDataset(np_data, transform=train_transform)\n",
        "\n",
        "\"\"\"# Split the data into train and validation sets \"\"\"\n",
        "\n",
        "n_total = len(train_dataset)\n",
        "n_train = int(n_total * 0.8)\n",
        "n_val = n_total - n_train\n",
        "train_data, val_data = random_split(train_dataset, [0.8, 0.2])\n",
        "\n",
        "\"\"\"## Visualize one sample\"\"\"\n",
        "\n",
        "img, label = train_dataset[100]\n",
        "print(img.shape)\n",
        "visualization(img, label)\n",
        "\n",
        "\"\"\"# Create data loaders for the train and validation sets\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "\"\"\"# Define the neural network model architecture\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = torchvision.models.googlenet(weights=torchvision.models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, train_dataset.number_of_classes())\n",
        "model.to(device)\n",
        "\n",
        "\"\"\"# Define loss and optimizer\"\"\"\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(device)\n",
        "\n",
        "\"\"\"# Train the model\"\"\"\n",
        "\n",
        "def evaluate(model, loader, device, criterion, mode='validation'):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, predictions = outputs.max(1)\n",
        "      total_correct += (labels == predictions).sum()\n",
        "  loss = total_loss / total\n",
        "  accuracy = total_correct / total\n",
        "  print(f'{mode} epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "\n",
        "# model = model.to(device)\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total_l = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total += images.size(0)\n",
        "    _, predictions = outputs.max(1)\n",
        "    total_correct += (predictions == labels).sum()\n",
        "    total_loss += loss.item() * images.size(0)\n",
        "  accuracy = total_correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f'Train epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "  evaluate(model, val_loader, device, criterion, mode='valid')\n",
        "  print('---------')\n",
        "  torch.save(model.state_dict(), f'model_v4_{epoch}.pt')\n",
        "\n",
        "torch.save(model.state_dict(), 'googlenet.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "4DWzYp9P44SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet18"
      ],
      "metadata": {
        "id": "w-xR46dJ4-kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Classifier_ResNet18.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1q4iDBgYax7aH96Bb5sO10TR4FS1Q_95z\n",
        "\"\"\"\n",
        "\n",
        "# Author: Banafsheh Khazali & Shokoofa Ghods\n",
        "# Date: March 06, 2023\n",
        "\n",
        "\"\"\"## Libraries\"\"\"\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip -q \"/content/drive/MyDrive/data/Dataset.zip\" -d \"data\"\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "np_data = data.values\n",
        "\n",
        "filename = '/content/drive/MyDrive/train/'\n",
        "X = np.empty(shape=(4135,224,224,3), dtype= np.uint8)\n",
        "for i in range(4135):\n",
        "  image = Image.open(filename + np_data[i][0]).resize((224,224))\n",
        "  img = np.array(image)\n",
        "  X[i] = np.array(image)\n",
        "\n",
        "\"\"\"# Define Transformers\"\"\"\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p = 0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.3),\n",
        "    transforms.RandomGrayscale(0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.2),\n",
        "    # transforms.RandomInvert(0.2),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.2),\n",
        "])\n",
        "\n",
        "\"\"\"# Map images to their labels\"\"\"\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.x[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label)\n",
        "        \n",
        "        # Return the image and label as tensors\n",
        "        return image, label\n",
        "\n",
        "    def number_of_classes(self):\n",
        "      return self.y.max() + 1\n",
        "\n",
        "def visualization(image, label=0):\n",
        "  plt.figure(figsize= (10,8))\n",
        "  plt.imshow(image.permute(1,2,0))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"# Load the train dataset from the folder\"\"\"\n",
        "\n",
        "train_dataset = CustomDataset(X,np_data[:,1] , transform=train_transform)\n",
        "\n",
        "\"\"\"# Split the data into train and validation sets \"\"\"\n",
        "\n",
        "train_data, val_data = random_split(train_dataset, [0.8, 0.2])\n",
        "\n",
        "\"\"\"## Visualize one sample\"\"\"\n",
        "\n",
        "img, label = train_dataset[106]\n",
        "print(img.shape)\n",
        "visualization(img)\n",
        "\n",
        "\"\"\"# Create data loaders for the train and validation sets\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        "    \n",
        ")\n",
        "\n",
        "\"\"\"# Define the neural network model architecture\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 100)\n",
        "model.to(device)\n",
        "\n",
        "# Fine-tune the pre-trained model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "\"\"\"# Define loss and optimizer\"\"\"\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(device)\n",
        "\n",
        "\"\"\"# Train the model\"\"\"\n",
        "\n",
        "def evaluate(model, loader, device, criterion, mode='validation'):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, predictions = outputs.max(1)\n",
        "      total_correct += (labels == predictions).sum()\n",
        "  loss = total_loss / total\n",
        "  accuracy = total_correct / total\n",
        "  print(f'{mode} epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "\n",
        "\n",
        "\n",
        "# model = model.to(device)\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total_l = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total += images.size(0)\n",
        "    _, predictions = outputs.max(1)\n",
        "    total_correct += (predictions == labels).sum()\n",
        "    total_loss += loss.item() * images.size(0)\n",
        "  accuracy = total_correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f'Train epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "  evaluate(model, val_loader, device, criterion, mode='valid')\n",
        "  print('---------')\n",
        "  torch.save(model.state_dict(), f'model_v4_{epoch}.pt')\n",
        "\n",
        "torch.save(model.state_dict(), 'resnet18.pt')"
      ],
      "metadata": {
        "id": "m2dsNArg5OM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DenseNet"
      ],
      "metadata": {
        "id": "P3q9eSCo5b4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Classifier_DenseNet_finetune.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1zdWCJTk4LoluOKm70smMH1LiLY8M4ciU\n",
        "\"\"\"\n",
        "\n",
        "# Author: Banafsheh Khazali & Shokoofa Ghods\n",
        "# Date: March 06, 2023\n",
        "\n",
        "\"\"\"## Libraries\"\"\"\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip -q \"/content/drive/MyDrive/data/Dataset.zip\" -d \"data\"\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "np_data = data.values\n",
        "\n",
        "filename = '/content/drive/MyDrive/train/'\n",
        "X = np.empty(shape=(4135,224,224,3), dtype= np.uint8)\n",
        "for i in range(4135):\n",
        "  image = Image.open(filename + np_data[i][0]).resize((224,224))\n",
        "  img = np.array(image)\n",
        "  X[i] = np.array(image)\n",
        "\n",
        "\"\"\"# Define Transformers\"\"\"\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p = 0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.3),\n",
        "    transforms.RandomGrayscale(0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.2),\n",
        "    # transforms.RandomInvert(0.2),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.2),\n",
        "])\n",
        "\n",
        "\"\"\"# Map images to their labels\"\"\"\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.x[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label)\n",
        "        \n",
        "        # Return the image and label as tensors\n",
        "        return image, label\n",
        "\n",
        "    def number_of_classes(self):\n",
        "      return self.y.max() + 1\n",
        "\n",
        "def visualization(image, label=0):\n",
        "  plt.figure(figsize= (10,8))\n",
        "  plt.imshow(image.permute(1,2,0))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"# Load the train dataset from the folder\"\"\"\n",
        "\n",
        "train_dataset = CustomDataset(X,np_data[:,1] , transform=train_transform)\n",
        "\n",
        "\"\"\"# Split the data into train and validation sets \"\"\"\n",
        "\n",
        "train_data, val_data = random_split(train_dataset, [0.8, 0.2])\n",
        "\n",
        "\"\"\"## Visualize one sample\"\"\"\n",
        "\n",
        "img, label = train_dataset[106]\n",
        "print(img.shape)\n",
        "visualization(img)\n",
        "\n",
        "\"\"\"# Create data loaders for the train and validation sets\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        "    \n",
        ")\n",
        "\n",
        "\"\"\"# Define the neural network model architecture\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = torchvision.models.densenet121(pretrained=True)\n",
        "\n",
        "# Replace last fully connected layer with a new one\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = torch.nn.Linear(num_ftrs, train_dataset.number_of_classes())\n",
        "model.to(device)\n",
        "\n",
        "# \"\"\"## FineTuning\n",
        "\n",
        "# we first freeze all layers except for the last one, and trains only the last layer for a few epochs. The we unfreeze all layers, and train the whole model for more epochs.\n",
        "# \"\"\"\n",
        "\n",
        "# # Freeze all layers except for the last one\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "# model.classifier.requires_grad = True\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# # Train the last layer\n",
        "# num_epochs = 20\n",
        "# for epoch in range(num_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(train_loader, 0):\n",
        "#         inputs, labels = data\n",
        "#         inputs = inputs.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# # Unfreeze all layers\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "\"\"\"# Define loss and optimizer\"\"\"\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(device)\n",
        "\n",
        "\"\"\"# Train the model\"\"\"\n",
        "\n",
        "def evaluate(model, loader, device, criterion, mode='validation'):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, predictions = outputs.max(1)\n",
        "      total_correct += (labels == predictions).sum()\n",
        "  loss = total_loss / total\n",
        "  accuracy = total_correct / total\n",
        "  print(f'{mode} epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "\n",
        "# model = model.to(device)\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total_l = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total += images.size(0)\n",
        "    _, predictions = outputs.max(1)\n",
        "    total_correct += (predictions == labels).sum()\n",
        "    total_loss += loss.item() * images.size(0)\n",
        "  accuracy = total_correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f'Train epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "  evaluate(model, val_loader, device, criterion, mode='valid')\n",
        "  print('---------')\n",
        "  torch.save(model.state_dict(), f'model_v4_{epoch}.pt')\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'densenet.pt')"
      ],
      "metadata": {
        "id": "SJupWHRq52vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DenseNet with FineTuning\n",
        "\n"
      ],
      "metadata": {
        "id": "gxiOXDtq6MIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Classifier_DenseNet_finetune (1).ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1MXh8gCj8bzR3t9SaP2CmGyOEGwXJjJ1w\n",
        "\"\"\"\n",
        "\n",
        "# Author: Banafsheh Khazali & Shokoofa Ghods\n",
        "# Date: March 06, 2023\n",
        "\n",
        "\"\"\"## Libraries\"\"\"\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip -q \"/content/drive/MyDrive/data/Dataset.zip\" -d \"data\"\n",
        "\n",
        "data = pd.read_csv('data/train.csv')\n",
        "np_data = data.values\n",
        "Y = np_data[:,1]\n",
        "\n",
        "filename = 'data/'\n",
        "X = np.empty(shape=(4135,224,224,3), dtype= np.uint8)\n",
        "for i in range(4135):\n",
        "  image = Image.open(filename + np_data[i][0]).resize((224,224))\n",
        "  img = np.array(image)\n",
        "  X[i] = np.array(image)\n",
        "\n",
        "\"\"\"# Define Transformers\"\"\"\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p = 0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.3),\n",
        "    transforms.RandomGrayscale(0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.2),\n",
        "    # transforms.RandomInvert(0.2),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.2),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(0.1),\n",
        "    # transforms.RandomVerticalFlip(0.1),\n",
        "    # transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "    # transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.2),\n",
        "])\n",
        "\n",
        "\"\"\"# Map images to their labels\"\"\"\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.x[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label)\n",
        "        \n",
        "        # Return the image and label as tensors\n",
        "        return image, label\n",
        "\n",
        "    def number_of_classes(self):\n",
        "      return self.y.max() + 1\n",
        "\n",
        "def visualization(image, label=0):\n",
        "  plt.figure(figsize= (10,8))\n",
        "  plt.imshow(image.permute(1,2,0))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"# Split the data into train and validation sets \"\"\"\n",
        "\n",
        "#since the augmentation for each data is different we split first then pass it to the dataset \n",
        "x_train, x_val, y_train, y_val = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"# Load the train dataset from the folder\"\"\"\n",
        "\n",
        "train_dataset = CustomDataset(x_train, y_train , transform=train_transform)\n",
        "val_dataset = CustomDataset(x_val, y_val , transform=val_transform)\n",
        "\n",
        "\"\"\"## Visualize one sample\"\"\"\n",
        "\n",
        "img, label = val_dataset[106]\n",
        "print(img.shape)\n",
        "visualization(img)\n",
        "\n",
        "\"\"\"# Create data loaders for the train and validation sets\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        "    \n",
        ")\n",
        "\n",
        "\"\"\"# Define the neural network model architecture\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = torchvision.models.densenet121(pretrained=True, )\n",
        "\n",
        "# Replace last fully connected layer with a new one\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = torch.nn.Linear(num_ftrs, train_dataset.number_of_classes())\n",
        "model.to(device)\n",
        "\n",
        "\"\"\"## FineTuning\n",
        "\n",
        "we first freeze all layers except for the last one, and trains only the last layer for a few epochs. The we unfreeze all layers, and train the whole model for more epochs.\n",
        "\"\"\"\n",
        "\n",
        "list(model.classifier.parameters())\n",
        "\n",
        "# Freeze all layers except for the last one\n",
        "for param in list(model.classifier.parameters()):\n",
        "    param.requires_grad = True\n",
        "# model.classifier.requires_grad = True\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the last layer\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Unfreeze all layers, in this phase we train the model again to fune tune parameters while we have preserved the parameters model has been learned during the last pre-training\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\"\"\"# Define loss and optimizer\"\"\"\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(device)\n",
        "\n",
        "\"\"\"# Train the model\"\"\"\n",
        "\n",
        "def evaluate(model, loader, device, criterion, mode='validation'):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, predictions = outputs.max(1)\n",
        "      total_correct += (labels == predictions).sum()\n",
        "  loss = total_loss / total\n",
        "  accuracy = total_correct / total\n",
        "  print(f'{mode} epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "\n",
        "# model = model.to(device)\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total_l = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total += images.size(0)\n",
        "    _, predictions = outputs.max(1)\n",
        "    total_correct += (predictions == labels).sum()\n",
        "    total_loss += loss.item() * images.size(0)\n",
        "  accuracy = total_correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f'Train epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "  evaluate(model, val_loader, device, criterion, mode='valid')\n",
        "  print('---------')\n",
        "  torch.save(model.state_dict(), f'model_v4_{epoch}.pt')\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'dense_finetune.pt')"
      ],
      "metadata": {
        "id": "GC3hPmAU6HcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EffiecientNet**"
      ],
      "metadata": {
        "id": "V5Wn-XX67J66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Classifier_EfficientNet.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1DeVfcwE5M4dT1WM6D6s05PNDS89Up2ax\n",
        "\"\"\"\n",
        "\n",
        "# Author: Banafsheh Khazali and Shokoofa Ghods\n",
        "# Date: March 06, 2023\n",
        "\n",
        "\"\"\"## Libraries\"\"\"\n",
        "\n",
        "!pip install git+https://github.com/lukemelas/EfficientNet-PyTorch\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip -q \"/content/drive/MyDrive/data/Dataset.zip\" -d \"data\"\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "data\n",
        "np_data = data.values\n",
        "\n",
        "\"\"\"## Load all data in a numpy array\"\"\"\n",
        "\n",
        "filename = '/content/drive/MyDrive/train/'\n",
        "X = np.empty(shape=(4135,224,224,3), dtype= np.uint8)\n",
        "for i in range(4135):\n",
        "  image = Image.open(filename + np_data[i][0]).resize((224,224))\n",
        "  img = np.array(image)\n",
        "  X[i] = np.array(image)\n",
        "\n",
        "\"\"\"# Define Transformers\"\"\"\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p = 0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.3),\n",
        "    transforms.RandomGrayscale(0.2),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.2),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.2),\n",
        "])\n",
        "\n",
        "\"\"\"# Map images to their labels\"\"\"\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.x[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label)\n",
        "        \n",
        "        # Return the image and label as tensors\n",
        "        return image, label\n",
        "\n",
        "    def number_of_classes(self):\n",
        "      return self.y.max() + 1\n",
        "\n",
        "def visualization(image, label=0):\n",
        "  plt.figure(figsize= (10,8))\n",
        "  plt.imshow(image.permute(1,2,0))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"# Load the train dataset from the folder\"\"\"\n",
        "\n",
        "train_dataset = CustomDataset(X,np_data[:,1] , transform=train_transform)\n",
        "\n",
        "\"\"\"# Split the data into train and validation sets \"\"\"\n",
        "\n",
        "train_data, val_data = random_split(train_dataset, [0.8, 0.2])\n",
        "\n",
        "\"\"\"## Visualize one sample\"\"\"\n",
        "\n",
        "img, label = train_dataset[106]\n",
        "print(img.shape)\n",
        "visualization(img)\n",
        "\n",
        "\"\"\"# Create data loaders for the train and validation sets\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        "    \n",
        ")\n",
        "\n",
        "\"\"\"# Using EfficientNet\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Load EfficientNet model with pretrained weights\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Replace last fully connected layer with a new one\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = torch.nn.Linear(num_ftrs, train_dataset.number_of_classes())\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\"\"\"# Define loss and optimizer\"\"\"\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(device)\n",
        "\n",
        "\"\"\"# Train the model\"\"\"\n",
        "\n",
        "def evaluate(model, loader, device, criterion, mode='validation'):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, predictions = outputs.max(1)\n",
        "      total_correct += (labels == predictions).sum()\n",
        "  loss = total_loss / total\n",
        "  accuracy = total_correct / total\n",
        "  print(f'{mode} epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "\n",
        "# model = model.to(device)\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  total_loss = 0\n",
        "  total_l = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total += images.size(0)\n",
        "    _, predictions = outputs.max(1)\n",
        "    total_correct += (predictions == labels).sum()\n",
        "    total_loss += loss.item() * images.size(0)\n",
        "  accuracy = total_correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f'Train epoch {epoch+1}: Loss({loss:6.4f}) Accuracy ({accuracy:6.4f})')\n",
        "  evaluate(model, val_loader, device, criterion, mode='valid')\n",
        "  print('---------')\n",
        "  torch.save(model.state_dict(), f'model_v4_{epoch}.pt')\n",
        "\n",
        "torch.save(model.state_dict(), 'efficient.pt')"
      ],
      "metadata": {
        "id": "eG57L7cb7Na2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Learning**"
      ],
      "metadata": {
        "id": "xnKy59qV5zZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "\n",
        "for i in range(3):\n",
        "  l.append(torch.tensor(pd.read_csv(f'prediction{i+1}.csv')['predicted'], dtype= float))\n",
        "en = torch.mode(torch.stack(l), dim = 0)\n",
        "for in range(len(predictions)):\n",
        "  predictions[i]['predicted'] = int(en.values[i].item())"
      ],
      "metadata": {
        "id": "DAn89xhQ5y1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**"
      ],
      "metadata": {
        "id": "dJMuz8zI7Rsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/best_eff.pt\")\n",
        "model = torch.load('/content/drive/MyDrive/best_eff.pt')\n",
        "test_csv = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/test/'\n",
        "test_files = os.listdir(test_dir)\n",
        "\n",
        "model.eval()\n",
        "from torchvision.transforms import ToTensor\n",
        "predictions = []\n",
        "\n",
        "# Define data transformation pipeline for test set\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "  \n",
        "])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for file in test_files:\n",
        "        image_path = os.path.join(test_dir, file)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = transform(image)\n",
        "        # image_tensor = ToTensor()(image_tensor)\n",
        "        image_tensor = image_tensor.to(device) \n",
        "        output = model(image_tensor.unsqueeze(0))\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        predictions.append({'id': f\"test/{file}\",\n",
        "                            'predicted': predicted.item()})\n",
        "        \n",
        "\n",
        "# Save predictions in CSV file\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df.to_csv('/content/drive/MyDrive/predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "IB5wWq3B6dBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}